Day 15 â€” Decision Trees & Random Forests (R)

â€¢ CART (Classification and Regression Trees)
  - Rule-based, non-parametric models
  - Easy to interpret and visualize
  - High variance â†’ prone to overfitting

â€¢ Random Forests
  - Ensemble of many CART trees
  - Uses bootstrapped samples and random feature selection
  - Reduces variance and improves out-of-sample performance
  - Less interpretable than a single tree

â€¢ Model behavior insights
  - Trees help explain data structure
  - Forests prioritize prediction stability
  - Accuracy alone is not sufficient for evaluation

ðŸ“Š Model evaluation
â€¢ Confusion Matrix
â€¢ Sensitivity & Specificity
â€¢ ROC Curves
â€¢ Comparison between single trees and ensembles

ðŸ›  Tools & Libraries
â€¢ rpart
â€¢ rpart.plot
â€¢ randomForest
â€¢ ROCR
â€¢ caret

Assignment questions can be found here:

https://ocw.mit.edu/courses/15-071-the-analytics-edge-spring-2017/pages/trees/assignment-4/
